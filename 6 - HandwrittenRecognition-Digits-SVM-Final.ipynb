{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(type(digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "print(digits.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "print(type(digits.data))\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(64,)\n",
      "[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(type(digits.data[0]))\n",
    "print(digits.data[0].shape)\n",
    "print(digits.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(1, 5):\n",
    "    plt.subplot(2,2, i)\n",
    "    plt.imshow(digits.data[i].reshape(8, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "print(digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1347, 64) (1347,) (450, 64) (450,)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, digits.target, test_size= 0.25 )\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "done in %0.3fs 9.00764513015747\n"
     ]
    }
   ],
   "source": [
    "# Train a SVM classification model\n",
    "from time import time\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#clf = SVC(C= 1, gamma = 0.1, verbose=True, kernel='rbf')\n",
    "#Tuning: Model selection\n",
    "param_grid = {\n",
    "               'C': [1e-3, 1e-2, 1, 1e2],\n",
    "              'gamma': [0.0001, 0.001, 0.1, 1], \n",
    "               'kernel': ['linear', 'rbf'],\n",
    "             }\n",
    "\n",
    "clf = GridSearchCV( SVC(), param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"done in %0.3fs\" , (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9933333333333333\n",
      "Best parameters selected from Grid search {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X_test, y_test))\n",
    "print(\"Best parameters selected from Grid search\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of support vectors (673,)\n",
      "Dual coeffecients (9, 673)\n"
     ]
    }
   ],
   "source": [
    "print(\"Indices of support vectors\", clf.best_estimator_.support_.shape)\n",
    "print(\"Dual coeffecients\", clf.best_estimator_.dual_coef_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of support vectors per each class: [38 78 62 69 64 66 48 67 90 91]\n",
      "\n",
      "Indices of support vectors [  25   95  129  135  143  156  196  238  249  305  312  313  365  398\n",
      "  410  426  440  466  604  606  615  654  821  831  856  896  962  963\n",
      "  968  984 1012 1023 1084 1118 1183 1232 1258 1283    0   69   89  134\n",
      "  145  147  154  162  163  183  197  224  258  268  298  337  386  441\n",
      "  465  498  506  507  508  516  535  570  573  579  597  641  649  684\n",
      "  685  694  695  699  702  704  706  728  748  757  785  788  804  834\n",
      "  864  865  882  889  902  904  918  919  929  935  965  969 1046 1051\n",
      " 1061 1066 1098 1135 1140 1143 1151 1168 1201 1203 1206 1209 1221 1263\n",
      " 1274 1278 1284 1291    7   28   71  111  112  125  133  144  148  153\n",
      "  160  186  187  262  270  293  300  304  323  354  360  377  378  389\n",
      "  435  446  452  456  457  470  524  526  564  575  602  610  626  670\n",
      "  676  680  727  756  773  799  863  867  872  874  880  884  931  975\n",
      " 1121 1152 1208 1231 1240 1250 1254 1273 1298 1344    9   36   53   54\n",
      "   68  136  152  208  215  261  308  327  355  361  400  407  496  500\n",
      "  519  521  543  552  557  559  571  572  614  639  752  766  810  823\n",
      "  824  844  850  910  922  937  939  976  981  996 1019 1022 1026 1027\n",
      " 1031 1036 1043 1049 1073 1083 1087 1127 1137 1179 1219 1223 1225 1228\n",
      " 1229 1234 1241 1262 1309 1310 1324 1339 1346   44   79  100  159  173\n",
      "  180  212  216  228  277  303  319  320  328  344  368  373  380  395\n",
      "  397  463  476  478  480  487  491  502  534  536  553  560  616  667\n",
      "  673  688  712  719  726  729  761  768  779  800  802  805  826  827\n",
      "  836  892  895  897  898  907  917  948  971 1053 1077 1085 1106 1108\n",
      " 1249 1253 1290    3   23   24   64   72   85  110  119  140  155  225\n",
      "  260  273  285  296  315  356  381  416  417  493  518  527  569  574\n",
      "  596  621  637  647  663  669  672  697  747  771  775  790  806  807\n",
      "  809  819  878  923  928  932  967  973 1040 1042 1071 1074 1078 1089\n",
      " 1107 1115 1123 1125 1131 1160 1199 1227 1276 1294 1326 1336 1337    8\n",
      "   26   84   90  116  188  190  276  301  341  363  391  393  414  461\n",
      "  471  483  485  566  620  627  651  707  716  741  744  755  777  797\n",
      "  812  820  837  890  947  952  979  999 1144 1145 1175 1182 1197 1233\n",
      " 1270 1277 1286 1288 1331   19   20   55   73  114  115  124  130  137\n",
      "  141  177  189  207  241  265  275  288  290  338  353  402  403  404\n",
      "  418  427  442  475  517  611  623  634  636  690  722  731  738  745\n",
      "  749  817  818  868  885  886  987  992  997 1001 1002 1013 1021 1065\n",
      " 1069 1086 1093 1094 1142 1165 1176 1177 1178 1185 1204 1205 1255 1306\n",
      " 1320 1334    6   16   21   32   37   57   62   65   74   81   82   92\n",
      "   93   99  105  107  118  158  181  204  227  254  291  307  317  325\n",
      "  329  330  331  348  369  371  408  419  424  429  430  444  462  477\n",
      "  479  540  544  545  547  548  555  558  565  576  586  589  599  600\n",
      "  635  640  655  661  711  733  734  758  793  811  828  838  843  847\n",
      "  866  903  953  990 1030 1048 1057 1090 1092 1101 1113 1141 1149 1180\n",
      " 1196 1200 1214 1279 1280 1281 1299 1317    4   34   80  102  131  132\n",
      "  171  175  178  192  203  211  230  234  237  239  252  289  343  387\n",
      "  399  420  422  423  434  437  450  455  459  460  473  492  505  514\n",
      "  515  554  563  593  603  607  612  645  646  664  691  692  700  714\n",
      "  723  762  765  781  784  787  798  832  839  840  846  851  869  883\n",
      "  905  906  911  946  972  988 1000 1007 1017 1028 1029 1034 1044 1068\n",
      " 1072 1102 1150 1173 1217 1218 1226 1236 1251 1252 1304 1315 1319 1341\n",
      " 1343]\n",
      "\n",
      "Dual coeffecients [ 0.00000000e+00  0.00000000e+00  1.33807056e-01  0.00000000e+00\n",
      "  0.00000000e+00  4.31169933e-01  3.07946410e-01  1.21471160e-01\n",
      "  1.64143183e-01  0.00000000e+00  2.56404328e-01  3.64291433e-03\n",
      "  1.10145279e-01  8.20967951e-02  0.00000000e+00  2.68105362e-01\n",
      "  0.00000000e+00  1.61951724e-01  5.31220052e-01  1.48365833e-01\n",
      "  7.41684389e-01  1.78399409e-01  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  3.64449348e-01\n",
      "  0.00000000e+00  5.10929811e-01  0.00000000e+00  4.53364162e-01\n",
      "  0.00000000e+00  0.00000000e+00  8.16988380e-01  0.00000000e+00\n",
      "  2.28960082e-01  0.00000000e+00 -0.00000000e+00 -2.59934400e-01\n",
      " -3.69392400e-01 -0.00000000e+00 -3.61162570e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -5.74568194e-02\n",
      " -1.43594464e-01 -0.00000000e+00 -0.00000000e+00 -3.96803408e-02\n",
      " -0.00000000e+00 -0.00000000e+00 -4.31875735e-02 -2.63100995e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -1.20222083e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -6.53210282e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -2.41883958e-01 -1.79866080e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -3.51642967e-03 -0.00000000e+00 -0.00000000e+00 -4.48732983e-02\n",
      " -0.00000000e+00 -2.29601178e-01 -1.69937317e-01 -0.00000000e+00\n",
      " -4.05202251e-03 -0.00000000e+00 -0.00000000e+00 -3.63100970e-01\n",
      " -0.00000000e+00 -2.52220625e-01 -5.45116965e-02 -0.00000000e+00\n",
      " -1.68712577e-01 -6.39990963e-01 -0.00000000e+00 -1.64909242e-01\n",
      " -1.21383283e-01 -8.38276719e-02 -0.00000000e+00 -0.00000000e+00\n",
      " -2.74849131e-01 -0.00000000e+00 -0.00000000e+00 -1.45605582e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.05463158e-01\n",
      " -1.04957353e-01 -0.00000000e+00 -1.00151404e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -1.50889746e-01 -0.00000000e+00\n",
      " -2.27225373e-01 -6.96062097e-02 -9.32402705e-01 -0.00000000e+00\n",
      " -2.52153948e-01 -5.16547388e-02 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -1.00121317e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -6.53120056e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -6.58758017e-02 -0.00000000e+00 -0.00000000e+00 -1.37895554e-02\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -2.06455944e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -8.40058225e-02 -0.00000000e+00\n",
      " -4.17600662e-02 -8.79319924e-02 -1.50399159e-01 -1.86890508e-01\n",
      " -2.41227188e-01 -2.11045739e-01 -2.03754737e-01 -3.66767064e-01\n",
      " -3.03549933e-01 -1.27301496e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -2.38366644e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -3.49131089e-02 -2.57110023e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -1.52815953e-01 -0.00000000e+00 -3.54485780e-01 -5.22689265e-01\n",
      " -0.00000000e+00 -1.71594418e-01 -0.00000000e+00 -4.88284535e-01\n",
      " -3.37400024e-02 -0.00000000e+00 -1.67721954e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -2.96081891e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.95629914e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -9.70625281e-02 -0.00000000e+00\n",
      " -0.00000000e+00 -2.31970730e-01 -4.96089895e-02 -1.85769869e-01\n",
      " -0.00000000e+00 -9.20027122e-03 -0.00000000e+00 -9.75386730e-02\n",
      " -0.00000000e+00 -1.59232554e-01 -4.57968237e-01 -7.93600309e-02\n",
      " -0.00000000e+00 -0.00000000e+00 -9.42893349e-02 -0.00000000e+00\n",
      " -2.93354232e-01 -0.00000000e+00 -2.08607433e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -1.88062860e-01 -0.00000000e+00 -3.12290732e-01\n",
      " -6.02476874e-01 -0.00000000e+00 -4.68248077e-01 -2.32851880e-01\n",
      " -0.00000000e+00 -4.10385985e-02 -0.00000000e+00 -3.19515602e-01\n",
      " -1.98492863e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -5.16249854e-01 -0.00000000e+00 -1.63156283e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -4.83648535e-03 -1.00000000e+00 -1.36477149e-02 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -2.12423397e-02 -0.00000000e+00\n",
      " -0.00000000e+00 -3.36604031e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.45436556e-01 -8.33051690e-02\n",
      " -0.00000000e+00 -3.22604808e-02 -0.00000000e+00 -1.22676086e-01\n",
      " -3.35019694e-02 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.86973251e-01 -3.36991690e-02\n",
      " -5.24275654e-02 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -2.25973066e-01 -2.44026010e-01 -0.00000000e+00 -1.29398832e-01\n",
      " -1.00000000e+00 -2.70175864e-01 -0.00000000e+00 -4.22686960e-01\n",
      " -2.61968472e-01 -7.62221286e-02 -2.03183472e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -8.77486109e-02 -2.10606648e-01 -4.33200079e-01 -0.00000000e+00\n",
      " -3.66212349e-01 -1.90874913e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -3.86401324e-02 -1.05252026e-01\n",
      " -0.00000000e+00 -9.92417019e-02 -0.00000000e+00 -2.49829694e-01\n",
      " -1.38784368e-01 -9.55135645e-02 -0.00000000e+00 -0.00000000e+00\n",
      " -2.38499079e-01 -1.42613882e-01 -1.43547408e-01 -1.73055084e-01\n",
      " -5.15977634e-01 -0.00000000e+00 -0.00000000e+00 -4.36682903e-01\n",
      " -0.00000000e+00 -1.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -1.58382815e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -1.17267156e-01 -9.00584888e-02 -0.00000000e+00 -8.17676599e-01\n",
      " -2.56656451e-01 -4.63972933e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -2.66960234e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.21075220e-02\n",
      " -0.00000000e+00 -0.00000000e+00 -2.05075043e-01 -6.43473718e-02\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -5.78723567e-01\n",
      " -2.40296427e-01 -6.76681775e-01 -7.17890820e-02 -0.00000000e+00\n",
      " -0.00000000e+00 -4.84960876e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -1.41444817e-01 -0.00000000e+00 -0.00000000e+00 -2.65012432e-01\n",
      " -0.00000000e+00 -3.61638641e-01 -0.00000000e+00 -5.49398962e-02\n",
      " -0.00000000e+00 -3.36924646e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -1.46044394e-01 -0.00000000e+00 -0.00000000e+00 -3.33682414e-02\n",
      " -0.00000000e+00 -0.00000000e+00 -2.66983543e-01 -0.00000000e+00\n",
      " -2.52345720e-01 -0.00000000e+00 -1.31356976e-01 -3.35944707e-02\n",
      " -1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -5.96892529e-01\n",
      " -1.69617133e-01 -6.68410667e-01 -0.00000000e+00 -8.56952927e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -6.71003519e-01 -1.35766963e-01 -2.66166653e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.63219396e-02 -2.02276288e-01\n",
      " -4.79087698e-01 -0.00000000e+00 -6.54076650e-03 -0.00000000e+00\n",
      " -0.00000000e+00 -3.17836097e-01 -1.12687019e-01 -9.91355828e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -6.52073520e-01 -7.56242793e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -1.02848714e-02 -2.47959299e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -1.34591384e-01 -1.26092483e-01\n",
      " -6.10876464e-02 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -1.05782919e-01 -4.92729977e-01 -3.44895284e-01 -0.00000000e+00\n",
      " -5.48628522e-02 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -1.06572856e-01 -1.63333562e-01 -0.00000000e+00 -3.89575184e-01\n",
      " -0.00000000e+00 -2.55517330e-02 -0.00000000e+00 -0.00000000e+00\n",
      " -6.20029879e-03 -2.27865976e-01 -2.08063974e-01 -6.78250805e-02\n",
      " -6.84232029e-01 -3.25303672e-01 -1.19279480e-01 -9.34096683e-02\n",
      " -6.89451201e-02 -0.00000000e+00 -0.00000000e+00 -2.93021588e-01\n",
      " -1.07180942e-01 -0.00000000e+00 -0.00000000e+00 -1.24392468e-02\n",
      " -4.03279064e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -2.07356889e-03 -3.56987432e-02 -2.55146394e-02 -0.00000000e+00\n",
      " -1.58188621e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -3.21926552e-02 -4.06990104e-02 -2.34948480e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -2.09264092e-01 -0.00000000e+00 -2.43649397e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -6.60900367e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -2.70194403e-01 -1.77041514e-01 -2.90759717e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -1.43020755e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -4.00455895e-01 -5.65163719e-02 -0.00000000e+00\n",
      " -0.00000000e+00 -3.41966075e-02 -6.73946931e-02 -1.83296958e-01\n",
      " -0.00000000e+00 -1.12129192e-01 -0.00000000e+00 -5.74289792e-02\n",
      " -8.00023484e-02 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -1.45539197e-01\n",
      " -0.00000000e+00 -3.07280882e-02 -9.76822622e-02 -1.03932371e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -5.18736072e-03 -1.21777481e-01\n",
      " -1.61137262e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -1.06229726e-01 -0.00000000e+00\n",
      " -1.04081292e-02 -0.00000000e+00 -5.75704055e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -3.57493457e-02 -5.98140247e-01 -0.00000000e+00\n",
      " -8.73425541e-04 -0.00000000e+00 -0.00000000e+00 -1.69463864e-03\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -3.65240098e-02 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -2.17258741e-01 -7.06317033e-02 -0.00000000e+00\n",
      " -0.00000000e+00 -3.08235488e-02 -2.11722015e-01 -0.00000000e+00\n",
      " -5.04311790e-01 -1.03530508e-01 -0.00000000e+00 -1.18302954e-02\n",
      " -8.94900354e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -1.06751362e-01 -8.98308506e-02 -0.00000000e+00 -6.02588359e-01\n",
      " -3.02971104e-01 -1.04670029e-01 -6.60291400e-01 -7.42228331e-02\n",
      " -0.00000000e+00 -6.78264260e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -3.88337399e-01 -0.00000000e+00 -1.02432303e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -7.83158469e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -1.11289227e-01 -0.00000000e+00 -6.99387459e-02\n",
      " -0.00000000e+00 -6.24260111e-02 -5.53777103e-02 -0.00000000e+00\n",
      " -8.63298067e-02 -0.00000000e+00 -0.00000000e+00 -1.36091969e-01\n",
      " -0.00000000e+00 -2.98717305e-01 -0.00000000e+00 -1.84506347e-01\n",
      " -1.07441641e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37176805e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.24929231e-01 -1.71059119e-01\n",
      " -0.00000000e+00 -9.25780188e-02 -0.00000000e+00 -2.93135877e-02\n",
      " -0.00000000e+00 -1.33550801e-01 -1.67006084e-03 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -9.79828965e-01 -4.80959146e-02\n",
      " -2.64427105e-01 -2.36650884e-01 -2.72351691e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -5.48654679e-02 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -1.05989606e-01 -1.32725076e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -2.73138065e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -5.38421885e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -3.79371451e-01 -2.17785129e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -3.37231572e-01 -1.24671127e-01 -0.00000000e+00\n",
      " -0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of support vectors per each class:\", clf.best_estimator_.n_support_ )\n",
    "print(\"\\nIndices of support vectors\", clf.best_estimator_.support_)\n",
    "print(\"\\nDual coeffecients\", clf.best_estimator_.dual_coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.01313052, 0.07023344, 0.01350636, 0.07139201, 0.01472006,\n",
       "        0.07404032, 0.01292992, 0.10920353, 0.0118875 , 0.07315917,\n",
       "        0.01298332, 0.07463884, 0.0128087 , 0.08147378, 0.01241312,\n",
       "        0.11589036, 0.01139631, 0.02530522, 0.01207571, 0.02238889,\n",
       "        0.01066537, 0.0856082 , 0.01220465, 0.11910725, 0.01052861,\n",
       "        0.01295633, 0.0121479 , 0.02913151, 0.01052575, 0.08335681,\n",
       "        0.0121418 , 0.1213726 ]),\n",
       " 'std_fit_time': array([2.00672697e-03, 3.87187659e-03, 3.96741948e-03, 9.05050184e-04,\n",
       "        3.78281079e-03, 3.52496938e-03, 5.07893991e-03, 4.47413867e-03,\n",
       "        3.23988766e-03, 2.19442156e-03, 6.32170718e-04, 1.53352342e-03,\n",
       "        2.87624531e-03, 5.29541995e-03, 4.83464760e-04, 2.70962461e-03,\n",
       "        1.60633681e-03, 5.33612571e-03, 3.14423979e-03, 5.42840862e-04,\n",
       "        8.82793737e-04, 3.97771671e-03, 7.44637050e-04, 2.91215592e-03,\n",
       "        8.25588775e-04, 3.75323191e-03, 3.12090607e-03, 9.66357773e-04,\n",
       "        8.18870987e-04, 3.94426542e-03, 3.12636622e-03, 4.03857709e-05]),\n",
       " 'mean_score_time': array([0.0019999 , 0.02466035, 0.00086579, 0.02434578, 0.00160789,\n",
       "        0.02209158, 0.00323405, 0.0307457 , 0.0020483 , 0.02366009,\n",
       "        0.00280933, 0.0250577 , 0.00145307, 0.02312717, 0.00378923,\n",
       "        0.03166809, 0.00263753, 0.01674714, 0.0024848 , 0.01903768,\n",
       "        0.00367637, 0.02594953, 0.00338449, 0.03036199, 0.00363703,\n",
       "        0.00970488, 0.00202103, 0.01134982, 0.00322657, 0.02707849,\n",
       "        0.00243154, 0.03035641]),\n",
       " 'std_score_time': array([1.67331280e-03, 4.43528984e-03, 1.06066944e-03, 3.91355320e-03,\n",
       "        1.44109244e-03, 1.34141083e-03, 3.36740115e-03, 3.75605450e-05,\n",
       "        3.14537122e-03, 3.16465770e-03, 4.08494079e-04, 9.86048729e-04,\n",
       "        1.22740124e-03, 3.15883820e-03, 7.50552326e-04, 1.20808621e-03,\n",
       "        2.95266854e-03, 3.53311449e-03, 2.95252457e-03, 8.60479432e-04,\n",
       "        4.55152833e-03, 3.11498617e-03, 4.84905799e-04, 2.64572013e-05,\n",
       "        4.50251038e-03, 8.26453062e-04, 3.11916053e-03, 1.00974446e-03,\n",
       "        3.95173090e-03, 3.50715002e-03, 3.91730625e-03, 3.16114626e-05]),\n",
       " 'param_C': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 100.0, 100.0, 100.0, 100.0, 100.0,\n",
       "                    100.0, 100.0, 100.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.0001, 0.0001, 0.001, 0.001, 0.1, 0.1, 1, 1, 0.0001,\n",
       "                    0.0001, 0.001, 0.001, 0.1, 0.1, 1, 1, 0.0001, 0.0001,\n",
       "                    0.001, 0.001, 0.1, 0.1, 1, 1, 0.0001, 0.0001, 0.001,\n",
       "                    0.001, 0.1, 0.1, 1, 1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.001, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 0.001, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 0.001, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 0.001, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 0.001, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 0.001, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 0.001, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 0.001, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 0.01, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 100.0, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 100.0, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 100.0, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 100.0, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 100.0, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 100.0, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 100.0, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 100.0, 'gamma': 1, 'kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.97037037, 0.20740741, 0.97037037, 0.20740741, 0.97037037,\n",
       "        0.10740741, 0.97037037, 0.20740741, 0.97777778, 0.20740741,\n",
       "        0.97777778, 0.20740741, 0.97777778, 0.10740741, 0.97777778,\n",
       "        0.20740741, 0.97777778, 0.96296296, 0.97777778, 0.98518519,\n",
       "        0.97777778, 0.12592593, 0.97777778, 0.20740741, 0.97777778,\n",
       "        0.97407407, 0.97777778, 0.98148148, 0.97777778, 0.12592593,\n",
       "        0.97777778, 0.20740741]),\n",
       " 'split1_test_score': array([0.98888889, 0.1037037 , 0.98888889, 0.1037037 , 0.98888889,\n",
       "        0.1037037 , 0.98888889, 0.1037037 , 0.97037037, 0.1037037 ,\n",
       "        0.97037037, 0.1037037 , 0.97037037, 0.1037037 , 0.97037037,\n",
       "        0.1037037 , 0.97037037, 0.96666667, 0.97037037, 0.99259259,\n",
       "        0.97037037, 0.1037037 , 0.97037037, 0.1037037 , 0.97037037,\n",
       "        0.98888889, 0.97037037, 0.9962963 , 0.97037037, 0.1037037 ,\n",
       "        0.97037037, 0.1037037 ]),\n",
       " 'split2_test_score': array([0.96654275, 0.10408922, 0.96654275, 0.10408922, 0.96654275,\n",
       "        0.10408922, 0.96654275, 0.10408922, 0.96654275, 0.10408922,\n",
       "        0.96654275, 0.10408922, 0.96654275, 0.10408922, 0.96654275,\n",
       "        0.10408922, 0.96654275, 0.96654275, 0.96654275, 0.97769517,\n",
       "        0.96654275, 0.10408922, 0.96654275, 0.10408922, 0.96654275,\n",
       "        0.97769517, 0.96654275, 0.97769517, 0.96654275, 0.10780669,\n",
       "        0.96654275, 0.10408922]),\n",
       " 'split3_test_score': array([0.98141264, 0.10408922, 0.98141264, 0.10408922, 0.98141264,\n",
       "        0.10408922, 0.98141264, 0.10408922, 0.9739777 , 0.10408922,\n",
       "        0.9739777 , 0.10408922, 0.9739777 , 0.10408922, 0.9739777 ,\n",
       "        0.10408922, 0.97769517, 0.97026022, 0.97769517, 0.98884758,\n",
       "        0.97769517, 0.10408922, 0.97769517, 0.10408922, 0.97769517,\n",
       "        0.98884758, 0.97769517, 0.98884758, 0.97769517, 0.10780669,\n",
       "        0.97769517, 0.10408922]),\n",
       " 'split4_test_score': array([0.98513011, 0.10408922, 0.98513011, 0.10408922, 0.98513011,\n",
       "        0.10408922, 0.98513011, 0.10408922, 0.98141264, 0.10408922,\n",
       "        0.98141264, 0.10408922, 0.98141264, 0.10408922, 0.98141264,\n",
       "        0.10408922, 0.97769517, 0.98141264, 0.97769517, 0.98513011,\n",
       "        0.97769517, 0.10408922, 0.97769517, 0.10408922, 0.97769517,\n",
       "        0.99256506, 0.97769517, 0.98513011, 0.97769517, 0.10408922,\n",
       "        0.97769517, 0.10408922]),\n",
       " 'mean_test_score': array([0.97846895, 0.12467575, 0.97846895, 0.12467575, 0.97846895,\n",
       "        0.10467575, 0.97846895, 0.12467575, 0.97401625, 0.12467575,\n",
       "        0.97401625, 0.12467575, 0.97401625, 0.10467575, 0.97401625,\n",
       "        0.12467575, 0.97401625, 0.96956905, 0.97401625, 0.98589013,\n",
       "        0.97401625, 0.10837946, 0.97401625, 0.12467575, 0.97401625,\n",
       "        0.98441415, 0.97401625, 0.98589013, 0.97401625, 0.10986645,\n",
       "        0.97401625, 0.12467575]),\n",
       " 'std_test_score': array([0.00859573, 0.0413661 , 0.00859573, 0.0413661 , 0.00859573,\n",
       "        0.00137396, 0.00859573, 0.0413661 , 0.00525362, 0.0413661 ,\n",
       "        0.00525362, 0.0413661 , 0.00525362, 0.00137396, 0.00525362,\n",
       "        0.0413661 , 0.00469816, 0.00635564, 0.00469816, 0.00493764,\n",
       "        0.00469816, 0.0087745 , 0.00469816, 0.0413661 , 0.00469816,\n",
       "        0.00718579, 0.00469816, 0.00639071, 0.00469816, 0.00821885,\n",
       "        0.00469816, 0.0413661 ]),\n",
       " 'rank_test_score': array([ 4, 21,  4, 21,  4, 31,  4, 21,  8, 21,  8, 21,  8, 31,  8, 21,  8,\n",
       "        20,  8,  1,  8, 30,  8, 21,  8,  3,  8,  1,  8, 29,  8, 21])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression score: 0.962222\n",
      "done in %0.3fs 1.2495229244232178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors, linear_model\n",
    "logistic = linear_model.LogisticRegression(solver='lbfgs', max_iter=7000,\n",
    "                                           multi_class='multinomial', verbose=2)\n",
    "\n",
    "t0 = time()\n",
    "print('LogisticRegression score: %f'\n",
    "      % logistic.fit(X_train, y_train).score(X_test, y_test))\n",
    "print(\"done in %0.3fs\" , (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on GridSearchCV in module sklearn.model_selection._search object:\n",
      "\n",
      "class GridSearchCV(BaseSearchCV)\n",
      " |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |  \n",
      " |  Exhaustive search over specified parameter values for an estimator.\n",
      " |  \n",
      " |  Important members are fit, predict.\n",
      " |  \n",
      " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"score_samples\", \"predict\", \"predict_proba\",\n",
      " |  \"decision_function\", \"transform\" and \"inverse_transform\" if they are\n",
      " |  implemented in the estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated grid-search over a parameter grid.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <grid_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object.\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_grid : dict or list of dictionaries\n",
      " |      Dictionary with parameters names (`str`) as keys and lists of\n",
      " |      parameter settings to try as values, or a list of such\n",
      " |      dictionaries, in which case the grids spanned by each dictionary\n",
      " |      in the list are explored. This enables searching over any sequence\n",
      " |      of parameter settings.\n",
      " |  \n",
      " |  scoring : str, callable, list, tuple or dict, default=None\n",
      " |      Strategy to evaluate the performance of the cross-validated model on\n",
      " |      the test set.\n",
      " |  \n",
      " |      If `scoring` represents a single score, one can use:\n",
      " |  \n",
      " |      - a single string (see :ref:`scoring_parameter`);\n",
      " |      - a callable (see :ref:`scoring`) that returns a single value.\n",
      " |  \n",
      " |      If `scoring` represents multiple scores, one can use:\n",
      " |  \n",
      " |      - a list or tuple of unique strings;\n",
      " |      - a callable returning a dictionary where the keys are the metric\n",
      " |        names and the values are the metric scores;\n",
      " |      - a dictionary with metric names as keys and callables a values.\n",
      " |  \n",
      " |      See :ref:`multimetric_grid_search` for an example.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of jobs to run in parallel.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |      .. versionchanged:: v0.20\n",
      " |         `n_jobs` default changed from 1 to None\n",
      " |  \n",
      " |  refit : bool, str, or callable, default=True\n",
      " |      Refit an estimator using the best found parameters on the whole\n",
      " |      dataset.\n",
      " |  \n",
      " |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
      " |      scorer that would be used to find the best parameters for refitting\n",
      " |      the estimator at the end.\n",
      " |  \n",
      " |      Where there are considerations other than maximum score in\n",
      " |      choosing a best estimator, ``refit`` can be set to a function which\n",
      " |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
      " |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      " |      according to the returned ``best_index_`` while the ``best_score_``\n",
      " |      attribute will not be available.\n",
      " |  \n",
      " |      The refitted estimator is made available at the ``best_estimator_``\n",
      " |      attribute and permits using ``predict`` directly on this\n",
      " |      ``GridSearchCV`` instance.\n",
      " |  \n",
      " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      " |      ``best_score_`` and ``best_params_`` will only be available if\n",
      " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      " |      scorer.\n",
      " |  \n",
      " |      See ``scoring`` parameter to know more about multiple metric\n",
      " |      evaluation.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          Support for callable added.\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, default=None\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 5-fold cross validation,\n",
      " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      " |      - :term:`CV splitter`,\n",
      " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`KFold` is used. These splitters are instantiated\n",
      " |      with `shuffle=False` so the splits will be the same across calls.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      " |  \n",
      " |  verbose : int\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |      - >1 : the computation time for each fold and parameter candidate is\n",
      " |        displayed;\n",
      " |      - >2 : the score is also displayed;\n",
      " |      - >3 : the fold and candidate parameter indexes are also displayed\n",
      " |        together with the starting time of the computation.\n",
      " |  \n",
      " |  pre_dispatch : int, or str, default=n_jobs\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A str, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  error_score : 'raise' or numeric, default=np.nan\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error.\n",
      " |  \n",
      " |  return_train_score : bool, default=False\n",
      " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      " |      scores.\n",
      " |      Computing training scores is used to get insights on how different\n",
      " |      parameter settings impact the overfitting/underfitting trade-off.\n",
      " |      However computing the scores on the training set can be computationally\n",
      " |      expensive and is not strictly required to select the parameters that\n",
      " |      yield the best generalization performance.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |      .. versionchanged:: 0.21\n",
      " |          Default value was changed from ``True`` to ``False``\n",
      " |  \n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import svm, datasets\n",
      " |  >>> from sklearn.model_selection import GridSearchCV\n",
      " |  >>> iris = datasets.load_iris()\n",
      " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      " |  >>> svc = svm.SVC()\n",
      " |  >>> clf = GridSearchCV(svc, parameters)\n",
      " |  >>> clf.fit(iris.data, iris.target)\n",
      " |  GridSearchCV(estimator=SVC(),\n",
      " |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
      " |  >>> sorted(clf.cv_results_.keys())\n",
      " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      " |   'param_C', 'param_kernel', 'params',...\n",
      " |   'rank_test_score', 'split0_test_score',...\n",
      " |   'split2_test_score', ...\n",
      " |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cv_results_ : dict of numpy (masked) ndarrays\n",
      " |      A dict with keys as column headers and values as columns, that can be\n",
      " |      imported into a pandas ``DataFrame``.\n",
      " |  \n",
      " |      For instance the below given table\n",
      " |  \n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      " |      +============+===========+============+=================+===+=========+\n",
      " |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |  \n",
      " |      will be represented by a ``cv_results_`` dict of::\n",
      " |  \n",
      " |          {\n",
      " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      " |                                       mask = [False False False False]...)\n",
      " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      " |                                      mask = [ True  True False False]...),\n",
      " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      " |                                       mask = [False False  True  True]...),\n",
      " |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
      " |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
      " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
      " |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
      " |          'rank_test_score'    : [2, 4, 3, 1],\n",
      " |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
      " |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
      " |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
      " |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
      " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      " |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
      " |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
      " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      " |          }\n",
      " |  \n",
      " |      NOTE\n",
      " |  \n",
      " |      The key ``'params'`` is used to store a list of parameter\n",
      " |      settings dicts for all the parameter candidates.\n",
      " |  \n",
      " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      " |      ``std_score_time`` are all in seconds.\n",
      " |  \n",
      " |      For multi-metric evaluation, the scores for all the scorers are\n",
      " |      available in the ``cv_results_`` dict at the keys ending with that\n",
      " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      " |  \n",
      " |  best_estimator_ : estimator\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if ``refit=False``.\n",
      " |  \n",
      " |      See ``refit`` parameter for more information on allowed values.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Mean cross-validated score of the best_estimator\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |      This attribute is not available if ``refit`` is a function.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  best_index_ : int\n",
      " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      " |      candidate parameter setting.\n",
      " |  \n",
      " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      " |      the parameter setting for the best model, that gives the highest\n",
      " |      mean score (``search.best_score_``).\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  scorer_ : function or a dict\n",
      " |      Scorer function used on the held out data to choose the best\n",
      " |      parameters for the model.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute holds the validated\n",
      " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      " |  \n",
      " |  n_splits_ : int\n",
      " |      The number of cross-validation splits (folds/iterations).\n",
      " |  \n",
      " |  refit_time_ : float\n",
      " |      Seconds used for refitting the best model on the whole dataset.\n",
      " |  \n",
      " |      This is present only if ``refit`` is not False.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  multimetric_ : bool\n",
      " |      Whether or not the scorers compute several metrics.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The parameters selected are those that maximize the score of the left out\n",
      " |  data, unless an explicit score is passed in which case it is used instead.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  See Also\n",
      " |  ---------\n",
      " |  ParameterGrid : Generates all the combinations of a hyperparameter grid.\n",
      " |  train_test_split : Utility function to split the data into a development\n",
      " |      set usable for fitting a GridSearchCV instance and an evaluation set\n",
      " |      for its final evaluation.\n",
      " |  sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
      " |      loss function.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GridSearchCV\n",
      " |      BaseSearchCV\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
      " |      Run fit with all sets of parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      groups : array-like of shape (n_samples,), default=None\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      " |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
      " |      \n",
      " |      **fit_params : dict of str -> object\n",
      " |          Parameters passed to the ``fit`` method of the estimator\n",
      " |  \n",
      " |  inverse_transform(self, Xt)\n",
      " |      Call inverse_transform on the estimator with the best found params.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements\n",
      " |      ``inverse_transform`` and ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Returns the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |  \n",
      " |  score_samples(self, X)\n",
      " |      Call score_samples on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``score_samples``.\n",
      " |      \n",
      " |      .. versionadded:: 0.24\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Data to predict on. Must fulfill input requirements\n",
      " |          of the underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples,)\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseSearchCV:\n",
      " |  \n",
      " |  classes_\n",
      " |  \n",
      " |  n_features_in_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
